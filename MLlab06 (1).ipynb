{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEwj9jieo7O5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A1. Define weights, learning rate, and activation functions\n",
        "w0 = 10\n",
        "w1 = 0.2\n",
        "w2 = -0.75\n",
        "learn_rate = 0.05\n",
        "\n",
        "# Step fn: if x>=0 then y=1 else y=0\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Bipolar step fn: if x>=0 then y=1 else y=-1\n",
        "def bipolar_step(x):\n",
        "    return -1 if x < 0 else 1\n",
        "\n",
        "# Sigmoid fn: y=1/(1+e^-x)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# ReLU fn\n",
        "def relu(x):\n",
        "    return max(0, x)\n",
        "\n",
        "# A2. Define perceptron training and plotting functions\n",
        "\n",
        "# Function to train perceptron\n",
        "def perceptron(inp, outp, w0, w1, w2, learn, active_fn, epochs=1000, converge=0.0002):\n",
        "    # Initialize weights\n",
        "    errors = []\n",
        "    W = np.array([w0, w1, w2])\n",
        "\n",
        "    # Loop through epochs\n",
        "    for epoch in range(epochs):\n",
        "        error_sq = 0\n",
        "        p = []\n",
        "        # Loop through input-output pairs\n",
        "        for input, out in zip(inp, outp):\n",
        "            weight_sum = W[0] + np.dot(input, W[1:])\n",
        "            predict = active_fn(weight_sum)\n",
        "            error = out - predict\n",
        "            error_sq += error ** 2\n",
        "            W[1:] += learn * error * input\n",
        "            W[0] += learn * error\n",
        "            p.append(predict)\n",
        "        errors.append(error_sq)\n",
        "        if error_sq <= converge:\n",
        "            break\n",
        "    return W, epoch, errors, p\n",
        "\n",
        "def a1(inp, out, w0, w1, w2, learn_rate):\n",
        "    # Function to train perceptron for AND gate with step function\n",
        "    Weight, n, errors, p = perceptron(inp, out, w0, w1, w2, learn_rate, step)\n",
        "\n",
        "    print(\"Converged at epoch \", n + 1)\n",
        "    print(\"Converged weights:\", Weight)\n",
        "    print(\"Predictions:\", p)\n",
        "    print('\\n')\n",
        "    # Plot errors\n",
        "    plt.plot(range(1, len(errors) + 1), errors)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Error vs Epochs')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# A3. Function to train perceptron for multiple activation functions\n",
        "def a2(inp, out, w0, w1, w2, learn_rate):\n",
        "  #list of activation functions\n",
        "    activate = [step, bipolar_step, sigmoid, relu]\n",
        "    activate_name = ['Step', 'Bipolar Step', 'Sigmoid', 'ReLU']\n",
        "    #for each activation fn\n",
        "    for active_fn, name in zip(activate, activate_name):\n",
        "        Weight, n, errors, p = perceptron(inp, out, w0, w1, w2, learn_rate, active_fn)\n",
        "        print('\\n', name)\n",
        "        print(\"Converged at epoch \", n + 1)\n",
        "        print(\"Converged weights:\", Weight)\n",
        "        print(\"Predictions:\", list(map(round, p)))\n",
        "        print('\\n')\n",
        "        plotg(name, errors)\n",
        "\n",
        "def plotg(name, errors):\n",
        "    # Function to plot errors vs epochs for different activation functions\n",
        "    plt.plot(range(1, len(errors) + 1), errors, label=name)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title(f\"Error vs Epoch \\n{name}\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# A4. Train perceptron for XOR gate\n",
        "def a4(inp, out, w0, w1, w2, learn_rate):\n",
        "    Weight, n, errors, p = perceptron(inp, out, w0, w1, w2, learn_rate, step)\n",
        "\n",
        "    print(\"Converged at epoch \", n + 1)\n",
        "    print(\"Converged weights:\", Weight)\n",
        "    print(\"Predictions:\", p)\n",
        "    print('\\n')\n",
        "    # Plot errors\n",
        "    plt.plot(range(1, len(errors) + 1), errors)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Error vs Epochs')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# A5. Define customer perceptron training function\n",
        "def customer_perceptron(X, y):\n",
        "    # Function to train a perceptron for customer classification\n",
        "    W = np.random.rand(X.shape[1])\n",
        "    learn_rate = 0.01\n",
        "    for epoch in range(1000):\n",
        "        for i in range(X.shape[0]):\n",
        "            z = np.dot(X[i], W)\n",
        "            predict = sigmoid(z)\n",
        "            error = y[i] - predict\n",
        "            W += learn_rate * error * sigmoid(predict) * X[i]\n",
        "    # Evaluation of the new weight\n",
        "    for i in range(X.shape[0]):\n",
        "        z = np.dot(X[i], W)\n",
        "        prediction = sigmoid(z)\n",
        "        print(f\"Customer_{i}: Predicted Value = {prediction > 0.5}\")\n",
        "    y_pred = [sigmoid(np.dot(X[i], W)) > 0.5 for i in range(X.shape[0])]\n",
        "    return y_pred\n",
        "\n",
        "# A6. Train perceptron for customer classification\n",
        "y_pred = customer_perceptron(X_norm, y)\n",
        "\n",
        "# A7. Define AND gate function for training\n",
        "def AND_gate(x1, x2, out):\n",
        "    # Function to implement AND gate logic\n",
        "    W = np.array([0.5, 0.5])  # Initialize weights\n",
        "    bias = -1.5  # Initialize bias\n",
        "\n",
        "    # Forward propagation\n",
        "    z = np.dot(W, [x1, x2]) + bias\n",
        "    p = sigmoid(z)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = p - out\n",
        "\n",
        "    # Backward propagation\n",
        "    delta = error * sigmoid(z)  # Corrected calculation of delta\n",
        "    dW = delta * np.array([x1, x2])  # Corrected calculation of weight_delta\n",
        "\n",
        "    # Update weights and bias based on learning rate\n",
        "    W -= learning_rate * dW\n",
        "    bias -= learning_rate * delta\n",
        "\n",
        "    return p\n",
        "\n",
        "# A8. Define XOR gate function for training\n",
        "def XOR_gate(x1, x2, target):\n",
        "    # Function to implement XOR gate logic\n",
        "    W = np.random.rand(2)  # Initialize weights\n",
        "    bias = np.random.rand()  # Initialize bias\n",
        "\n",
        "    learning_rate = 0.05\n",
        "    epochs = 1000\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward propagation\n",
        "        z = np.dot(W, [x1, x2]) + bias\n",
        "        p = sigmoid(z)\n",
        "\n",
        "        # Calculate the error\n",
        "        error = p - target\n",
        "\n",
        "        # Backward propagation\n",
        "        delta = error * sigmoid(p)\n",
        "        dW = delta * np.array([x1, x2])\n",
        "\n",
        "        # Update weights and bias based on learning rate\n",
        "        W -= learning_rate * dW\n",
        "        bias -= learning_rate * delta\n",
        "\n",
        "    return sigmoid(np.dot(W, [x1, x2]) + bias)\n",
        "\n",
        "# A9. Define perceptron function with multiple activation functions\n",
        "def perceptron(inputs, weights, activation):\n",
        "    # Function to implement perceptron with different activation functions\n",
        "    inputs = np.atleast_2d(inputs)\n",
        "    z = np.dot(weights, inputs.T)\n",
        "\n",
        "    if activation == \"step\":\n",
        "        output = 1 if z > 0 else 0\n",
        "    elif activation == \"sigmoid\":\n",
        "        output = 1 / (1 + np.exp(-z))\n",
        "    elif activation == \"relu\":\n",
        "        output = max(0, z)\n",
        "    elif activation == \"bipolar_step\":\n",
        "        output = 1 if z > 0 else -1\n",
        "    else:\n",
        "        raise ValueError(\"Invalid activation function provided.\")\n",
        "\n",
        "    return output\n",
        "\n",
        "def train_perceptron(data, target, epochs, learning_rate, initial_weights, activation):\n",
        "    # Function to train perceptron with chosen activation function\n",
        "    weights = initial_weights[:len(data[0])]\n",
        "    errors = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i, (x, y) in enumerate(zip(data, target)):\n",
        "            predicted = perceptron(x, weights, activation)\n",
        "            error = y - predicted\n",
        "            total_error += error ** 2\n",
        "            weights += learning_rate * error * x\n",
        "        average_error = total_error / len(data)\n",
        "        errors.append(average_error)\n",
        "        if average_error <= 0.002:\n",
        "            print(f\"Converged in {epoch + 1} epochs!\")\n",
        "            break\n",
        "\n",
        "    return weights, 0.0, errors\n",
        "\n",
        "def plot_errors(epochs, errors, title):\n",
        "    # Function to plot errors vs epochs for chosen activation function\n",
        "    plt.plot(epochs, errors)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# A10. Define AND and XOR functions using numpy bitwise operations\n",
        "def AND(x1, x2):\n",
        "    return np.bitwise_and(x1, x2)\n",
        "\n",
        "def XOR(x1, x2):\n",
        "    return np.bitwise_xor(x1, x2)\n"
      ],
      "metadata": {
        "id": "WhIOgiDRKvML"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}