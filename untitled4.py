# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oM5jDVQQqOG6E4swFB3UQqBKOsEMYEyw
"""

from google.colab import drive
drive.mount('/content/drive')

from glob import glob
import librosa
import pandas as pd
import numpy as np
from scipy.spatial.distance import minkowski
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import pywt
from matplotlib import pyplot as plt
from sklearn.metrics import classification_report
from sklearn.model_selection import learning_curve

def get_features(audios,labels):
  features_total=[]

  for i,x in enumerate(audios):  # Iterate over audio files and their corresponding labels
    y,sr=librosa.load(x)        # Load y-audio file and obtain the sampling rate (sr)
    D=librosa.stft(y)           # Compute Short-Time Fourier Transform (STFT) and convert to dB scale
    S_db=librosa.amplitude_to_db(np.abs(D),ref=np.max)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) # Extract Mel-frequency cepstral coefficients (MFCCs) #taking 13 features

    features=[]
    for f in mfccs:    # Calculate mean of each MFCC feature column
      feature=np.mean(f)
      features.append(feature)
    features.append(labels[i]) # Append the corresponding label to the feature vector
    features_total.append(features) # Append the feature vector to the list

  features_total=np.array(features_total) # Convert the list of feature vectors to a NumPy array

  features_total=pd.DataFrame(features_total,columns=["F1","F2","F3","F4","F5","F6","F7","F8","F9","F10","F11","F12","F13","Label"]) # Create a DataFrame with column names for features and label
  return features_total

POS ='/content/drive/MyDrive/aidataset/gunshot'
NEG = '/content/drive/MyDrive/aidataset/nongunshot'

pos = glob(POS + '/*.wav')
neg = glob(NEG + '/*.wav')

labels_1=[1]*len(pos) #list of files with label 1 - gunshot
labels_0=[0]*len(neg) #list of files with label 0 - non gunshot
fgun=get_features(pos,labels_1)
fnongun=get_features(neg,labels_0)

print(fgun)
print(fnongun)

# Repeat positive examples to match the number of negative examples
repeat_count = len(fnongun)// len(fgun)
remainder = len(fnongun) % len(fgun)

#nfgun = fgun
#for _ in range(repeat_count - 1):
    #nfgun = nfgun.concatenate(fgun)
nfgun = pd.concat([fgun] * repeat_count + [fgun.iloc[:remainder]]) #converting the files into a dataframe using pandas
data = pd.concat([fnongun, nfgun])
x = data.iloc[:, :-1] #feature vectors
y = data.iloc[:-1] #labels

import numpy as np
import matplotlib.pyplot as plt

def st_fn(x):
    if x >= 0:
      return 1
    else:
      return 0

def predict(X, W):
    m = st_fn(np.dot(X, W[1:]) + W[0])
    return m

def SumSqError(X, y, W):
    err = 0
    for i in range(len(X)):
        pre = predict(X[i], W)
        err += (y[i] - pre) ** 2
    return err

def trainPerceptron(X, y, W, lr, mepoch=1000):
    epoch = 0
    errHis = []
    while epoch < mepoch:
        perr = SumSqError(X, y, W) # previous error
        errHis.append(perr)
        for i in range(len(X)):
            pre = predict(X[i], W)
            e = (y[i] - pre)
            W[0] + W[1] * X[i, 0] + W[2] * X[i, 1]
            W[0] += lr * e
            W[1:] += lr * e * X[i]
        cerr = SumSqError(X, y, W) # current error
        if cerr == 0:
            break
        epoch += 1
    return W, epoch, errHis

X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 0, 0, 1])
w = np.array([10, 0.2, -0.75])
lr = 0.05

trainedWeights, epochs, errHis = trainPerceptron(X, y, w, lr)
plt.plot(range(epochs + 1), errHis)
plt.xlabel('Epochs')
plt.ylabel('Sum-Square-Error')
plt.title('Error vs Epochs')
plt.show()
print("Converged weights:", trainedWeights)
print("Number of epochs:", epochs)

print("Testing the perceptron:")
for i in range(len(X)):
    weighted_sum = trainedWeights[0] + trainedWeights[1] * X[i, 0] + trainedWeights[2] * X[i, 1]
    prediction = st_fn(weighted_sum)
    print(f"Input: {X[i]}, Prediction: {prediction}")



import numpy as np
import matplotlib.pyplot as plt
from math import exp


def step_activation(training_data,weights,alpha,epochs):
    errors = []
    epoch_num=0
    for epoch in range(epochs):
        error_sum = 0
        epoch_num+=1
        for x in training_data:
            pred=weights[0]*x[0] + weights[1]*x[1] + weights[2]*1
            output = pred>0
            error = x[2] - output
            weights[0] += alpha * error * x[0]
            weights[1] += alpha * error * x[1]
            weights[2] += alpha * error * 1
            error_sum += error**2
        errors.append(error_sum)
        if error_sum<=0.002:
            return weights,errors,epoch_num
    return weights,errors,epoch_num

def sigmoid_activation(training_data,weights,alpha,epochs):
    errors = []
    epoch_num=0
    for epoch in range(epochs):
        error_sum = 0
        epoch_num+=1
        for x in training_data:
            pred=weights[0]*x[0] + weights[1]*x[1] + weights[2]*1
            output = 1/(1+exp(-pred))
            error = x[2] - output
            weights[0] += alpha * error * x[0]
            weights[1] += alpha * error * x[1]
            weights[2] += alpha * error * 1
            error_sum += error**2
        errors.append(error_sum)
        if error_sum<=0.002:
            return weights,errors,epoch_num
    return weights,errors,epoch_num


def bi_polar_activation(training_data,weights,alpha,epochs):
    errors = []
    epoch_num=0
    for epoch in range(epochs):
        error_sum = 0
        epoch_num+=1
        for x in training_data:
            pred=weights[0]*x[0] + weights[1]*x[1] + weights[2]*1
            if pred>0:
                output = 1
            elif pred==0:
                output = 0
            else:
                output = -1
            error = x[2] - output
            weights[0] += alpha * error * x[0]
            weights[1] += alpha * error * x[1]
            weights[2] += alpha * error * 1
            error_sum += error**2
        errors.append(error_sum)
        if error_sum<=0.002:
            return weights,errors,epoch_num
    return weights,errors,epoch_num


def reLU_activation(training_data,weights,alpha,epochs):
    errors = []
    epoch_num=0
    for epoch in range(epochs):
        error_sum = 0
        epoch_num+=1
        for x in training_data:
            pred=weights[0]*x[0] + weights[1]*x[1] + weights[2]*1
            if pred>0:
                output = pred
            else:
                output = 0
            error = x[2] - output
            weights[0] += alpha * error * x[0]
            weights[1] += alpha * error * x[1]
            weights[2] += alpha * error * 1
            error_sum += error**2
        errors.append(error_sum)
        if error_sum<=0.002:
            return weights,errors,epoch_num
    return weights,errors,epoch_num

training_data = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0], [1, 1, 1]])
weights=[10, 0.2, -0.75]
alpha = 0.05
epochs = 1000

SWeights,SErrors,SEpoch_num=step_activation(training_data,weights,alpha,epochs)

# Plotting
print("Step_activation")
print(f"Finalized weights are W0:{SWeights[0]}, W1:{SWeights[0]},W2:{SWeights[0]}")
print(f"number of Epoches needed is {SEpoch_num}")
plt.plot(range(len(SErrors)), SErrors)
plt.xlabel('Epochs')
plt.ylabel('Sum-Square-Error')
plt.title('step activation')
plt.show()

Bweights,Berrors,Bepoch_num=bi_polar_activation(training_data,weights,alpha,epochs)

# Plotting
print("Bi-polar activation")
print(f"Finalized weights are W0:{Bweights[0]}, W1:{Bweights[0]},W2:{Bweights[0]}")
print(f"number of Epoches needed is {Bepoch_num}")
plt.plot(range(len(Berrors)), Berrors)
plt.xlabel('Epochs')
plt.ylabel('Sum-Square-Error')
plt.title('Bi-polar activation')
plt.show()

SiWeights,SiErrors,SiEpoch_num=sigmoid_activation(training_data,weights,alpha,epochs)

# Plotting
print("Sigmoid activation")
print(f"Finalized weights are W0:{SiWeights[0]}, W1:{SiWeights[0]},W2:{SiWeights[0]}")
print(f"number of Epoches needed is {SiEpoch_num}")
plt.plot(range(len(SiErrors)), SiErrors)
plt.xlabel('Epochs')
plt.ylabel('Sum-Square-Error')
plt.title('sigmoid activation')
plt.show()

RWeights,RErrors,REpoch_num=reLU_activation(training_data,weights,alpha,epochs)

# Plotting
print("reLU activation")
print(f"Finalized weights are W0:{RWeights[0]}, W1:{RWeights[0]},W2:{RWeights[0]}")
print(f"number of Epoches needed is {REpoch_num}")
plt.plot(range(len(RErrors)), RErrors)
plt.xlabel('Epochs')
plt.ylabel('Sum-Square-Error')
plt.title('reLU activation')
plt.show()